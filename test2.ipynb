# Real-Time Streaming Text-to-Speech System - PART 3
# Training Pipeline, Optimization, and Performance Monitoring
# Built from scratch for LibriSpeech train-clean-100

print("=" * 80)
print("üöÄ REAL-TIME STREAMING TTS SYSTEM - PART 3")
print("   Training Pipeline, Optimization & Performance Monitoring")
print("=" * 80)

# ==============================================================================
# CELL 15: Advanced Loss Functions and Metrics
# ==============================================================================

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast
import numpy as np
import time
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict, deque
import json
import os
from pathlib import Path
from tqdm import tqdm
import math

class TTSLossComputer:
    """Advanced loss computation for TTS training with multiple objectives"""
    
    def __init__(self, mel_loss_weight: float = 1.0, duration_loss_weight: float = 0.1,
                 alignment_loss_weight: float = 0.05, consistency_loss_weight: float = 0.02):
        self.mel_loss_weight = mel_loss_weight
        self.duration_loss_weight = duration_loss_weight
        self.alignment_loss_weight = alignment_loss_weight
        self.consistency_loss_weight = consistency_loss_weight
        
        # Loss functions
        self.mel_loss_fn = nn.L1Loss(reduction='mean')
        self.mel_loss_mse = nn.MSELoss(reduction='mean')
        self.duration_loss_fn = nn.MSELoss(reduction='mean')
        self.alignment_loss_fn = nn.L1Loss(reduction='mean')
        
        # Loss history for monitoring
        self.loss_history = defaultdict(list)
        
        print(f"üéØ TTSLossComputer initialized:")
        print(f"   Mel loss weight: {mel_loss_weight}")
        print(f"   Duration loss weight: {duration_loss_weight}")
        print(f"   Alignment loss weight: {alignment_loss_weight}")
        print(f"   Consistency loss weight: {consistency_loss_weight}")
    
    def compute_mel_loss(self, predicted_mel: torch.Tensor, target_mel: torch.Tensor,
                        mel_lengths: Optional[torch.Tensor] = None) -> torch.Tensor:
        """Compute mel-spectrogram loss with optional masking"""
        # Align sequences to same length
        min_len = min(predicted_mel.size(1), target_mel.size(1))
        pred_aligned = predicted_mel[:, :min_len, :]
        target_aligned = target_mel[:, :min_len, :]
        
        # Apply length masking if provided
        if mel_lengths is not None:
            batch_size = pred_aligned.size(0)
            mask = torch.arange(min_len).unsqueeze(0).expand(batch_size, -1)
            mask = mask < mel_lengths.unsqueeze(1)
            mask = mask.unsqueeze(-1).to(pred_aligned.device)
            
            pred_aligned = pred_aligned * mask
            target_aligned = target_aligned * mask
        
        # Combine L1 and L2 losses for better convergence
        l1_loss = self.mel_loss_fn(pred_aligned, target_aligned)
        l2_loss = self.mel_loss_mse(pred_aligned, target_aligned)
        
        return 0.7 * l1_loss + 0.3 * l2_loss
    
    def compute_duration_loss(self, predicted_durations: torch.Tensor, 
                            target_durations: torch.Tensor,
                            text_lengths: Optional[torch.Tensor] = None) -> torch.Tensor:
        """Compute duration prediction loss with masking"""
        if text_lengths is not None:
            # Create mask for valid tokens
            batch_size, max_len = predicted_durations.shape
            mask = torch.arange(max_len).unsqueeze(0).expand(batch_size, -1)
            mask = mask < text_lengths.unsqueeze(1)
            mask = mask.to(predicted_durations.device)
            
            # Apply mask
            predicted_masked = predicted_durations * mask
            target_masked = target_durations * mask
            
            # Compute loss only on valid tokens
            valid_elements = mask.sum()
            if valid_elements > 0:
                loss = F.mse_loss(predicted_masked, target_masked, reduction='sum') / valid_elements
            else:
                loss = torch.tensor(0.0, device=predicted_durations.device)
        else:
            loss = self.duration_loss_fn(predicted_durations, target_durations)
        
        return loss
    
    def compute_alignment_loss(self, predicted_durations: torch.Tensor,
                             target_mel_length: torch.Tensor) -> torch.Tensor:
        """Compute alignment consistency loss"""
        predicted_total_length = predicted_durations.sum(dim=1)
        target_total_length = target_mel_length.float()
        
        return self.alignment_loss_fn(predicted_total_length, target_total_length)
    
    def compute_consistency_loss(self, predicted_mel: torch.Tensor) -> torch.Tensor:
        """Compute temporal consistency loss for smoother outputs"""
        if predicted_mel.size(1) < 2:
            return torch.tensor(0.0, device=predicted_mel.device)
        
        # Compute differences between consecutive frames
        mel_diff = predicted_mel[:, 1:, :] - predicted_mel[:, :-1, :]
        
        # Penalize large differences (encourage smoothness)
        consistency_loss = torch.mean(torch.abs(mel_diff))
        
        return consistency_loss
    
    def compute_total_loss(self, predicted_mel: torch.Tensor, target_mel: torch.Tensor,
                          predicted_durations: torch.Tensor, target_durations: torch.Tensor,
                          text_lengths: Optional[torch.Tensor] = None,
                          mel_lengths: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """Compute all losses and return detailed breakdown"""
        
        # Individual loss components
        mel_loss = self.compute_mel_loss(predicted_mel, target_mel, mel_lengths)
        duration_loss = self.compute_duration_loss(predicted_durations, target_durations, text_lengths)
        
        # Alignment loss
        target_mel_length = torch.tensor([target_mel.size(1)] * target_mel.size(0), 
                                       device=target_mel.device)
        alignment_loss = self.compute_alignment_loss(predicted_durations, target_mel_length)
        
        # Consistency loss
        consistency_loss = self.compute_consistency_loss(predicted_mel)
        
        # Weighted total loss
        total_loss = (self.mel_loss_weight * mel_loss +
                     self.duration_loss_weight * duration_loss +
                     self.alignment_loss_weight * alignment_loss +
                     self.consistency_loss_weight * consistency_loss)
        
        # Store in history
        losses = {
            'total_loss': total_loss,
            'mel_loss': mel_loss,
            'duration_loss': duration_loss,
            'alignment_loss': alignment_loss,
            'consistency_loss': consistency_loss
        }
        
        for name, loss in losses.items():
            self.loss_history[name].append(loss.item())
        
        return losses
    
    def get_loss_summary(self, last_n: int = 100) -> Dict[str, float]:
        """Get summary statistics for recent losses"""
        summary = {}
        for name, history in self.loss_history.items():
            if history:
                recent = history[-last_n:]
                summary[name] = {
                    'mean': np.mean(recent),
                    'std': np.std(recent),
                    'min': np.min(recent),
                    'max': np.max(recent),
                    'latest': recent[-1] if recent else 0.0
                }
        return summary

class PerformanceMetrics:
    """Comprehensive performance metrics for TTS training"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.metrics = defaultdict(lambda: deque(maxlen=window_size))
        self.epoch_metrics = defaultdict(list)
        
    def update(self, **kwargs):
        """Update metrics with new values"""
        for name, value in kwargs.items():
            self.metrics[name].append(value)
    
    def get_current_stats(self) -> Dict[str, Dict[str, float]]:
        """Get current statistics for all metrics"""
        stats = {}
        for name, values in self.metrics.items():
            if values:
                values_list = list(values)
                stats[name] = {
                    'mean': np.mean(values_list),
                    'std': np.std(values_list),
                    'min': np.min(values_list),
                    'max': np.max(values_list),
                    'latest': values_list[-1]
                }
        return stats
    
    def end_epoch(self):
        """Store epoch-level statistics"""
        current_stats = self.get_current_stats()
        for name, stats in current_stats.items():
            self.epoch_metrics[name].append(stats['mean'])
    
    def plot_metrics(self, metrics_to_plot: List[str] = None, figsize: Tuple[int, int] = (15, 10)):
        """Plot training metrics"""
        if metrics_to_plot is None:
            metrics_to_plot = list(self.epoch_metrics.keys())
        
        n_metrics = len(metrics_to_plot)
        if n_metrics == 0:
            print("No metrics to plot")
            return
        
        n_cols = min(3, n_metrics)
        n_rows = (n_metrics + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)
        if n_rows == 1 and n_cols == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes
        else:
            axes = axes.flatten()
        
        for i, metric_name in enumerate(metrics_to_plot):
            if i < len(axes) and metric_name in self.epoch_metrics:
                ax = axes[i]
                values = self.epoch_metrics[metric_name]
                ax.plot(values, linewidth=2)
                ax.set_title(metric_name.replace('_', ' ').title())
                ax.set_xlabel('Epoch')
                ax.set_ylabel('Value')
                ax.grid(True, alpha=0.3)
        
        # Hide unused subplots
        for i in range(len(metrics_to_plot), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.show()

# ==============================================================================
# CELL 16: Advanced Training Pipeline
# ==============================================================================

class LibriSpeechTTSTrainer:
    """Production-ready training pipeline for LibriSpeech TTS"""
    
    def __init__(self, model, train_dataloader, val_dataloader, config):
        self.model = model
        self.train_dataloader = train_dataloader
        self.val_dataloader = val_dataloader
        self.config = config
        self.device = config.DEVICE
        
        # Move model to device
        self.model = self.model.to(self.device)
        
        # Loss computer
        self.loss_computer = TTSLossComputer(
            mel_loss_weight=config.MEL_LOSS_WEIGHT,
            duration_loss_weight=config.DURATION_LOSS_WEIGHT,
            alignment_loss_weight=config.ALIGNMENT_LOSS_WEIGHT
        )
        
        # Performance metrics
        self.metrics = PerformanceMetrics(window_size=100)
        
        # Optimizer with weight decay
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=config.LEARNING_RATE,
            betas=(0.9, 0.98),
            eps=1e-9,
            weight_decay=1e-6
        )
        
        # Advanced learning rate scheduler
        total_steps = len(train_dataloader) * config.NUM_EPOCHS
        self.scheduler = optim.lr_scheduler.OneCycleLR(
            self.optimizer,
            max_lr=config.LEARNING_RATE * 10,
            total_steps=total_steps,
            pct_start=0.1,
            div_factor=25,
            final_div_factor=10000,
            anneal_strategy='cos'
        )
        
        # Mixed precision training
        self.use_amp = config.USE_MIXED_PRECISION and torch.cuda.is_available()
        if self.use_amp:
            self.scaler = GradScaler()
            print("‚ö° Using mixed precision training (AMP)")
        
        # Training state
        self.current_epoch = 0
        self.global_step = 0
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        self.early_stopping_patience = 20
        
        # Training history
        self.train_loss_history = []
        self.val_loss_history = []
        
        # Gradient clipping
        self.max_grad_norm = config.GRAD_CLIP_NORM
        
        print(f"üèÉ‚Äç‚ôÇÔ∏è LibriSpeechTTSTrainer initialized:")
        print(f"   Device: {self.device}")
        print(f"   Mixed precision: {self.use_amp}")
        print(f"   Training batches: {len(train_dataloader)}")
        print(f"   Validation batches: {len(val_dataloader) if val_dataloader else 0}")
        print(f"   Total training steps: {total_steps}")
        print(f"   Max learning rate: {config.LEARNING_RATE * 10}")
    
    def train_step(self, batch) -> Dict[str, float]:
        """Single training step with mixed precision"""
        texts, mels, durations, text_lengths = batch
        texts = texts.to(self.device)
        mels = mels.to(self.device)
        durations = durations.to(self.device)
        text_lengths = text_lengths.to(self.device)
        
        # Forward pass
        self.optimizer.zero_grad()
        
        if self.use_amp:
            with autocast():
                predicted_mels, predicted_durations = self.model.forward(texts)
                losses = self.loss_computer.compute_total_loss(
                    predicted_mels, mels, predicted_durations, durations, text_lengths
                )
                total_loss = losses['total_loss']
            
            # Backward pass with scaling
            self.scaler.scale(total_loss).backward()
            
            # Gradient clipping
            self.scaler.unscale_(self.optimizer)
            grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
            
            # Optimizer step
            self.scaler.step(self.optimizer)
            self.scaler.update()
        else:
            predicted_mels, predicted_durations = self.model.forward(texts)
            losses = self.loss_computer.compute_total_loss(
                predicted_mels, mels, predicted_durations, durations, text_lengths
            )
            total_loss = losses['total_loss']
            
            # Backward pass
            total_loss.backward()
            
            # Gradient clipping
            grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
            
            # Optimizer step
            self.optimizer.step()
        
        # Scheduler step
        self.scheduler.step()
        
        # Prepare metrics
        step_metrics = {
            'total_loss': losses['total_loss'].item(),
            'mel_loss': losses['mel_loss'].item(),
            'duration_loss': losses['duration_loss'].item(),
            'alignment_loss': losses['alignment_loss'].item(),
            'consistency_loss': losses['consistency_loss'].item(),
            'learning_rate': self.scheduler.get_last_lr()[0],
            'grad_norm': grad_norm.item() if isinstance(grad_norm, torch.Tensor) else grad_norm
        }
        
        self.global_step += 1
        return step_metrics
    
    def validation_step(self, batch) -> Dict[str, float]:
        """Single validation step"""
        texts, mels, durations, text_lengths = batch
        texts = texts.to(self.device)
        mels = mels.to(self.device)
        durations = durations.to(self.device)
        text_lengths = text_lengths.to(self.device)
        
        with torch.no_grad():
            if self.use_amp:
                with autocast():
                    predicted_mels, predicted_durations = self.model.forward(texts)
                    losses = self.loss_computer.compute_total_loss(
                        predicted_mels, mels, predicted_durations, durations, text_lengths
                    )
            else:
                predicted_mels, predicted_durations = self.model.forward(texts)
                losses = self.loss_computer.compute_total_loss(
                    predicted_mels, mels, predicted_durations, durations, text_lengths
                )
        
        return {f"val_{name}": loss.item() for name, loss in losses.items()}
    
    def train_epoch(self) -> Dict[str, float]:
        """Train for one epoch"""
        self.model.train()
        epoch_metrics = defaultdict(list)
        
        # Progress bar
        pbar = tqdm(self.train_dataloader, desc=f"Epoch {self.current_epoch + 1}")
        
        for batch_idx, batch in enumerate(pbar):
            # Training step
            step_metrics = self.train_step(batch)
            
            # Update metrics
            for name, value in step_metrics.items():
                epoch_metrics[name].append(value)
            
            # Update progress bar
            if batch_idx % 10 == 0:
                current_lr = step_metrics['learning_rate']
                pbar.set_postfix({
                    'Loss': f"{step_metrics['total_loss']:.4f}",
                    'Mel': f"{step_metrics['mel_loss']:.4f}",
                    'Dur': f"{step_metrics['duration_loss']:.4f}",
                    'LR': f"{current_lr:.2e}",
                    'GradNorm': f"{step_metrics['grad_norm']:.2f}"
                })
            
            # Update live metrics
            self.metrics.update(**step_metrics)
            
            # Memory cleanup
            if batch_idx % 100 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # Compute epoch averages
        epoch_avg = {name: np.mean(values) for name, values in epoch_metrics.items()}
        return epoch_avg
    
    def validate_epoch(self) -> Dict[str, float]:
        """Validate for one epoch"""
        if self.val_dataloader is None:
            return {}
        
        self.model.eval()
        epoch_metrics = defaultdict(list)
        
        with torch.no_grad():
            for batch in tqdm(self.val_dataloader, desc="Validation"):
                step_metrics = self.validation_step(batch)
                
                for name, value in step_metrics.items():
                    epoch_metrics[name].append(value)
        
        # Compute averages
        epoch_avg = {name: np.mean(values) for name, values in epoch_metrics.items()}
        return epoch_avg
    
    def save_checkpoint(self, filepath: str, is_best: bool = False):
        """Save training checkpoint"""
        checkpoint = {
            'epoch': self.current_epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'train_loss_history': self.train_loss_history,
            'val_loss_history': self.val_loss_history,
            'config': {
                'vocab_size': self.config.VOCAB_SIZE,
                'hidden_dim': self.config.HIDDEN_DIM,
                'num_layers': self.config.NUM_LAYERS,
                'sample_rate': self.config.SAMPLE_RATE,
                'mel_dim': self.config.MEL_DIM
            }
        }
        
        if self.use_amp:
            checkpoint['scaler_state_dict'] = self.scaler.state_dict()
        
        torch.save(checkpoint, filepath)
        
        if is_best:
            best_path = str(Path(filepath).parent / 'best_model.pth')
            torch.save(checkpoint, best_path)
            print(f"üíæ Best model saved: {best_path}")
        
        print(f"üíæ Checkpoint saved: {filepath}")
    
    def load_checkpoint(self, filepath: str) -> bool:
        """Load training checkpoint"""
        try:
            checkpoint = torch.load(filepath, map_location=self.device)
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            
            self.current_epoch = checkpoint['epoch']
            self.global_step = checkpoint['global_step']
            self.best_val_loss = checkpoint['best_val_loss']
            self.train_loss_history = checkpoint.get('train_loss_history', [])
            self.val_loss_history = checkpoint.get('val_loss_history', [])
            
            if self.use_amp and 'scaler_state_dict' in checkpoint:
                self.scaler.load_state_dict(checkpoint['scaler_state_dict'])
            
            print(f"üìñ Checkpoint loaded: {filepath}")
            print(f"   Resuming from epoch {self.current_epoch}")
            print(f"   Global step: {self.global_step}")
            print(f"   Best validation loss: {self.best_val_loss:.4f}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Failed to load checkpoint: {e}")
            return False
    
    def train(self, num_epochs: int, save_dir: str = "./checkpoints", 
              save_freq: int = 5, validate_freq: int = 1) -> Dict[str, List[float]]:
        """Main training loop"""
        save_dir = Path(save_dir)
        save_dir.mkdir(exist_ok=True, parents=True)
        
        print(f"üöÄ Starting training for {num_epochs} epochs")
        print(f"   Save directory: {save_dir}")
        print(f"   Save frequency: every {save_freq} epochs")
        print(f"   Validation frequency: every {validate_freq} epochs")
        
        try:
            for epoch in range(self.current_epoch, self.current_epoch + num_epochs):
                self.current_epoch = epoch
                epoch_start_time = time.time()
                
                print(f"\nüìà Epoch {epoch + 1}/{self.current_epoch + num_epochs}")
                print("-" * 60)
                
                # Training
                train_metrics = self.train_epoch()
                self.train_loss_history.append(train_metrics['total_loss'])
                
                # Validation
                val_metrics = {}
                if epoch % validate_freq == 0:
                    val_metrics = self.validate_epoch()
                    if 'val_total_loss' in val_metrics:
                        self.val_loss_history.append(val_metrics['val_total_loss'])
                
                # Epoch timing
                epoch_time = time.time() - epoch_start_time
                
                # Print epoch summary
                print(f"‚úÖ Epoch {epoch + 1} completed in {epoch_time:.1f}s")
                print(f"   Train Loss: {train_metrics['total_loss']:.4f}")
                if val_metrics:
                    print(f"   Val Loss: {val_metrics.get('val_total_loss', 0):.4f}")
                print(f"   Learning Rate: {train_metrics['learning_rate']:.2e}")
                
                # Early stopping and best model saving
                if val_metrics and 'val_total_loss' in val_metrics:
                    val_loss = val_metrics['val_total_loss']
                    if val_loss < self.best_val_loss:
                        self.best_val_loss = val_loss
                        self.patience_counter = 0
                        is_best = True
                        print(f"   üèÜ New best validation loss: {val_loss:.4f}")
                    else:
                        self.patience_counter += 1
                        is_best = False
                        if self.patience_counter >= self.early_stopping_patience:
                            print(f"   ‚èπÔ∏è Early stopping triggered (patience: {self.early_stopping_patience})")
                            break
                else:
                    is_best = False
                
                # Save checkpoint
                if epoch % save_freq == 0 or is_best:
                    checkpoint_path = save_dir / f"checkpoint_epoch_{epoch + 1}.pth"
                    self.save_checkpoint(checkpoint_path, is_best=is_best)
                
                # Update epoch metrics
                self.metrics.end_epoch()
                
                # Plot progress periodically
                if epoch % (save_freq * 2) == 0 and epoch > 0:
                    self.plot_training_progress()
        
        except KeyboardInterrupt:
            print(f"\n‚èπÔ∏è Training interrupted at epoch {self.current_epoch + 1}")
            checkpoint_path = save_dir / "interrupted_checkpoint.pth"
            self.save_checkpoint(checkpoint_path)
        
        except Exception as e:
            print(f"\n‚ùå Training failed with error: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            # Final checkpoint
            final_path = save_dir / "final_checkpoint.pth"
            self.save_checkpoint(final_path)
            
            print(f"\nüéâ Training completed!")
            print(f"   Total epochs: {self.current_epoch + 1}")
            print(f"   Best validation loss: {self.best_val_loss:.4f}")
            print(f"   Final checkpoint: {final_path}")
        
        return {
            'train_loss': self.train_loss_history,
            'val_loss': self.val_loss_history
        }
    
    def plot_training_progress(self):
        """Plot training progress"""
        if len(self.train_loss_history) < 2:
            return
        
        plt.figure(figsize=(15, 5))
        
        # Loss plot
        plt.subplot(1, 3, 1)
        epochs = range(1, len(self.train_loss_history) + 1)
        plt.plot(epochs, self.train_loss_history, label='Training Loss', linewidth=2)
        if self.val_loss_history:
            val_epochs = range(1, len(self.val_loss_history) + 1)
            plt.plot(val_epochs, self.val_loss_history, label='Validation Loss', linewidth=2)
        plt.title('Training Progress')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Learning rate plot
        plt.subplot(1, 3, 2)
        if hasattr(self.metrics, 'epoch_metrics') and 'learning_rate' in self.metrics.epoch_metrics:
            lr_history = self.metrics.epoch_metrics['learning_rate']
            plt.plot(range(1, len(lr_history) + 1), lr_history, linewidth=2, color='orange')
            plt.title('Learning Rate Schedule')
            plt.xlabel('Epoch')
            plt.ylabel('Learning Rate')
            plt.yscale('log')
            plt.grid(True, alpha=0.3)
        
        # Gradient norm plot
        plt.subplot(1, 3, 3)
        if hasattr(self.metrics, 'epoch_metrics') and 'grad_norm' in self.metrics.epoch_metrics:
            grad_history = self.metrics.epoch_metrics['grad_norm']
            plt.plot(range(1, len(grad_history) + 1), grad_history, linewidth=2, color='green')
            plt.title('Gradient Norm')
            plt.xlabel('Epoch')
            plt.ylabel('Gradient Norm')
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

# ==============================================================================
# CELL 17: Model Evaluation and Testing
# ==============================================================================

class ModelEvaluator:
    """Comprehensive model evaluation and testing"""
    
    def __init__(self, model, text_processor, config):
        self.model = model
        self.text_processor = text_processor
        self.config = config
        self.device = config.DEVICE
        
        self.model.eval()
        
    def evaluate_single_sample(self, text: str, return_intermediate: bool = True) -> Dict[str, Any]:
        """Evaluate model on a single text sample"""
        # Tokenize text
        text_ids = self.text_processor.text_to_ids(text)
        text_tensor = torch.tensor([text_ids], dtype=torch.long).to(self.device)
        
        # Time the inference
        start_time = time.time()
        
        with torch.no_grad():
            results = self.model.inference(text_tensor, return_intermediate=return_intermediate)
        
        inference_time = time.time() - start_time
        
        # Add metadata
        results.update({
            'input_text': text,
            'input_tokens': text_ids,
            'inference_time': inference_time,
            'real_time_factor': results['audio_length'] / self.config.SAMPLE_RATE / inference_time
        })
        
        return results
    
    def evaluate_streaming_performance(self, text: str, buffer_size: int = 4) -> Dict[str, Any]:
        """Evaluate streaming performance with latency measurements"""
        words = text.split()
        
        # Initialize streaming
        self.model.reset_streaming_state()
        buffer = []
        chunk_times = []
        chunk_audio_lengths = []
        total_audio = []
